{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a49e93",
   "metadata": {},
   "source": [
    "## Regridding eORCA025 data onto eORCA0083 using xESMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e731738",
   "metadata": {},
   "source": [
    "What follows is a rehash of a few examples of how to use xESMF to regrid data (mostly from [roocs](https://github.com/roocs)). The objective is to regrid an eORCA025 data set on to the eORCA0083 grid for initial conditions to be used in the CANARI project. Usually my go to tool is SOSIE/SCRIP to regrid data, but I thought I'd venture into the Python realm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d421564-6608-4c69-aaa7-efbf423eb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['PROJ_LIB'] = '/dssgfs01/working/jdha/miniforge3/envs/analysis/share/proj' # avoid basemap import error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9ad4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cf_xarray as cfxr\n",
    "import xesmf as xe\n",
    "import scipy.sparse as sps\n",
    "import clisops.core as clore\n",
    "import clisops as cl\n",
    "import textwrap\n",
    "import math\n",
    "import copy as cp\n",
    "import warnings\n",
    "\n",
    "xr.set_options(display_style='html');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707d0891-2218-4a5d-9ad7-a560cc1e2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infill(arr_in, n_iter=None, bathy=None):\n",
    "    \"\"\"\n",
    "    Returns data with any NaNs replaced by iteratively taking the geometric\n",
    "    mean of surrounding points until all NaNs are removed or n_inter-ations\n",
    "    have been performed. Input data must be 2D and can include a\n",
    "    bathymetry array as to provide land barriers to the infilling.\n",
    "\n",
    "    Args:\n",
    "        arr_in          (ndarray): data array 2D\n",
    "        n_iter              (int): number of smoothing iterations\n",
    "        bathy           (ndarray): bathymetry array (land set to zero)\n",
    "\n",
    "    Returns:\n",
    "        arr_mod         (ndarray): modified data array\n",
    "    \"\"\"\n",
    "\n",
    "    # Check number of dims\n",
    "    if arr_in.ndim != 2:\n",
    "        raise ValueError(\"Array must have two dimensions\")\n",
    "\n",
    "    # Intial setup to prime things for the averaging loop\n",
    "    if bathy is None:\n",
    "        bathy = np.ones_like(arr_in, dtype=float)\n",
    "    if n_iter is None:\n",
    "        n_iter = np.inf\n",
    "    ind = np.where(np.logical_and(np.isnan(arr_in), np.greater(bathy, 0.)))\n",
    "    counter = 0\n",
    "    jpj, jpi = arr_in.shape\n",
    "    # Infill until all NaNs are removed or N interations completed\n",
    "    while np.sum(ind)>0 and counter<n_iter:\n",
    "\n",
    "        # TODO: include a check to see if number of NaNs is decreasing\n",
    "\n",
    "        # Create indices of neighbouring points\n",
    "        ind_e = cp.deepcopy(ind); ind_w = cp.deepcopy(ind)\n",
    "        ind_n = cp.deepcopy(ind); ind_s = cp.deepcopy(ind)\n",
    "\n",
    "        ind_e[1][:] = np.minimum(ind_e[1][:]+1, jpi-1)\n",
    "        ind_w[1][:] = np.maximum(ind_w[1][:]-1, 0    )\n",
    "        ind_n[0][:] = np.minimum(ind_n[0][:]+1, jpj-1)\n",
    "        ind_s[0][:] = np.maximum(ind_s[0][:]-1, 0    )\n",
    "\n",
    "        # Replace NaNs\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            arr_in[ind] = np.nanmean(np.vstack((arr_in[ind_e],\n",
    "                                                arr_in[ind_w],\n",
    "                                                arr_in[ind_n],\n",
    "                                                arr_in[ind_s])), axis=0)\n",
    "\n",
    "        # Find new indices for next loop\n",
    "        ind = np.where(np.logical_and(np.isnan(arr_in),\n",
    "                                      np.greater(bathy, 0.)))\n",
    "        counter += 1\n",
    "\n",
    "    return arr_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70113746-c260-4f83-904f-71a33f477e88",
   "metadata": {},
   "source": [
    "### Specify source grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f7b2c8-9cba-4fab-a489-bf09f8975728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source data\n",
    "src_fname = './src_data.nc'\n",
    "# source grid\n",
    "src_dom = './src_domain_cfg.nc'\n",
    "\n",
    "# create dataset\n",
    "ds_src_grid = xr.open_dataset(src_dom).isel(time_counter=0).rename({'glamt': 'lon', 'gphit': 'lat'})\n",
    "ds_src_grid = ds_src_grid.set_coords((\"lat\", \"lon\"))\n",
    "\n",
    "# create dataset\n",
    "ds_src_data = xr.open_dataset(src_fname).rename({'nav_lon': 'lon', 'nav_lat': 'lat'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dec5aa",
   "metadata": {},
   "source": [
    "### Specify destination grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe90c07-46ef-4dd9-bb3c-9e6ab1c39446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination grid\n",
    "dst_dom = './dst_domain_cfg.nc'\n",
    "\n",
    "# create dataset\n",
    "ds_dst_grid = xr.open_dataset(dst_dom).isel(time_counter=0).rename({'x': 'lon', 'y': 'lat'})\n",
    "ds_dst_grid = ds_dst_grid.set_coords((\"lat\", \"lon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca78206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the regridding weights\n",
    "regridder_eORCA0083=xe.Regridder(ds_src_grid, ds_dst_grid, 'bilinear', periodic=True, ignore_degenerate=True, unmapped_to_nan=True)\n",
    "fn = '/dssgfs01/working/jdha/regridder_eORCA025_to_eORCA0083.nc'\n",
    "regridder_eORCA0083.to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c76b1-af70-4845-9c83-db451a2229dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/dssgfs01/working/jdha/regridder_eORCA025_to_eORCA0083.nc'\n",
    "regridder_eORCA0083_loaded=xe.Regridder(ds_src_grid, ds_dst_grid, 'bilinear', periodic=True, ignore_degenerate=True, unmapped_to_nan=True, weights=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0035a5b-1f6c-4b08-b4fc-1e5133ffbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 2.0 work around\n",
    "regridder_eORCA0083_loaded.shape_in = tuple(map(int, regridder_eORCA0083_loaded.shape_in))\n",
    "regridder_eORCA0083_loaded.shape_out = tuple(map(int, regridder_eORCA0083_loaded.shape_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regridding temperature and salinity\n",
    "ds_toce = regridder_eORCA0083_loaded(ds_src_data.thetao_con[0,:,:,:]).to_dataset(name='toce')\n",
    "ds_soce = regridder_eORCA0083_loaded(ds_src_data.so_abs[0,:,:,:]).to_dataset(name='so')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a81354-94be-4d9c-9e7e-c451359bc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([ds_toce, ds_soce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0cd77c6-eaae-4db7-88ce-a8340af31a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.chunk({\"deptht\": 75, \"lat\": 128, \"lon\": 128})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29c4c7fa-b35c-43ea-9039-57939d5eb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop_vars({\"time_centered\",\"time_counter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89768b96-a655-4779-b9c5-339e7e6c4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compression settings for each variable\n",
    "compression = {\"zlib\": True, \"complevel\": 1}  # Enable deflation with level 5 compression\n",
    "encoding = {\n",
    "    \"toce\": compression,\n",
    "    \"so\": compression,\n",
    "}\n",
    "\n",
    "# Write to a compressed NetCDF file\n",
    "ds.to_netcdf(\"ICs_y1979m01.nc\", encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0f663-904b-4d03-8034-9b0be77dd6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
